{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Code of Conduct for Jupyter Notebook Template Usage\n",
                "\n",
                "## Introduction\n",
                "\n",
                "Welcome to our Jupyter Notebook environment. To ensure a productive and respectful environment, we have established a few ground rules. Please adhere to this Code of Conduct when using our Jupyter Notebook templates.\n",
                "\n",
                "## Guidelines\n",
                "\n",
                "### 1. **Notebook Structure**\n",
                "   - This notebook has a specifc structure that should be respected and not to be tempered with.\n",
                "\n",
                "### 2. **Responsible Resource Usage**\n",
                "   - Use computational resources judiciously.\n",
                "   - Avoid unnecessary computational tasks that can overload the system.\n",
                "\n",
                "## Reporting Issues\n",
                "\n",
                "If you encounter any issues or observe violations of this Code of Conduct, please report them to [jarcau.stefan.cristian@gmail.com](jarcau.stefan.cristian@gmail.com).\n",
                "\n",
                "## Conclusion\n",
                "\n",
                "By adhering to these guidelines, we can maintain a healthy, productive, and welcoming environment for all users. Thank you for your cooperation and happy coding!\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Getting the dataset from the database."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "v35iuYktjj9i"
            },
            "outputs": [],
            "source": [
                "import io\n",
                "import os\n",
                "import requests\n",
                "import pandas as pd\n",
                "\n",
                "url = os.getenv(\"DATASET_URL\")\n",
                "api = os.getenv(\"API\")\n",
                "\n",
                "response = requests.get(api + f\"?path={url}\")\n",
                "\n",
                "if response.status_code != 200:\n",
                "    raise Exception(response.content.decode(\"utf-8\"))\n",
                "\n",
                "df = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "H6NBPtQxRhNz"
            },
            "source": [
                "# See what is the target column for training the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "lx76zqLelzp1"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "pppcog65Rcei"
            },
            "source": [
                "# Encode literal columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "FkJG97J1nWrX"
            },
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "encoded_df = df\n",
                "\n",
                "le = LabelEncoder()\n",
                "\n",
                "for column in encoded_df.columns:\n",
                "  if isinstance(encoded_df[column][0], str):\n",
                "    encoded_df[column] = le.fit_transform(encoded_df[column])\n",
                "\n",
                "encoded_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Split the encoded_df in train and test subsets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "Zt-_SeugkPAt"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "train, test = train_test_split(encoded_df, test_size=0.1)\n",
                "\n",
                "X_train, y_train = train[[column for column in train.columns if column != os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")]], train[os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")]\n",
                "X_test, y_test = test[[column for column in test.columns if column != os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")]], test[os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "nIXaMas_OgvC"
            },
            "source": [
                "# Training and choosing the best model (You can modify the parameters of the model to fits the dataset best, or let them as they are)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "id": "6JwiIe6KqeXK"
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import cross_val_score, KFold\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.linear_model import Ridge, Lasso\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from xgboost import XGBRegressor\n",
                "from lightgbm import LGBMRegressor\n",
                "from tqdm import tqdm\n",
                "import numpy as np\n",
                "\n",
                "# Define the models you want to compare\n",
                "models = {\n",
                "    'SVR': SVR(random_state=42),\n",
                "    'Ridge': Ridge(random_state=42),\n",
                "    'Lasso': Lasso(random_state=42),\n",
                "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
                "    'Random Forest': RandomForestRegressor(n_estimators=200, random_state=42),\n",
                "    'KNN': KNeighborsRegressor(n_neighbors=len(np.unique(encoded_df[os.getenv(\"TARGET_COLUMN\").strip().replace(\"\\n\", \"\")])), random_state=42),\n",
                "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
                "    \"XGB Regressor\": XGBRegressor(tree_method=\"hist\", eval_metric='logloss', random_state=42),\n",
                "    \"LGBM Regressor\": LGBMRegressor(n_estimators=200, random_state=42) # Change the objective to multiclass if you see more then one class in the target column\n",
                "}\n",
                "\n",
                "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)  # You can modify the n_splits, to train the model better\n",
                "\n",
                "def cross_validate_model(model, X, y, cv):\n",
                "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
                "    return scores.mean()\n",
                "\n",
                "cv_results = {model_name: cross_validate_model(model, X_train, y_train, cv_strategy) for model_name, model in tqdm(models.items())}\n",
                "\n",
                "max = 0\n",
                "model_name = None\n",
                "\n",
                "for mn, score in cv_results.items():\n",
                "  if score > max:\n",
                "    model_name = mn\n",
                "    max = score\n",
                "\n",
                "models[model_name].fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "Rn9IWMuvOnr-"
            },
            "source": [
                "# Calculating the scores for the best model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "id": "5mh7JVRMr2Mq"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
                "\n",
                "if (\"model_name\" in locals() or \"model_name\" in globals()) and (\"models\" in locals() or \"models\" in globals()):\n",
                "  predictions = models[model_name].predict(X_test)\n",
                "\n",
                "  acc_score = accuracy_score(y_test, predictions)\n",
                "  mae = mean_absolute_error(y_test, predictions)\n",
                "  mse = mean_squared_error(y_test, predictions)\n",
                "  rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
                "\n",
                "  metrics = {\n",
                "      \"Mean Squared Error\": round(mse, 2),\n",
                "      \"Mean Absolute Error\": round(mae, 2),\n",
                "      \"Root Mean Squared Error\": round(rmse, 2),\n",
                "      \"Accuracy Score\": round(acc_score, 2)\n",
                "  }\n",
                "  \n",
                "  print(metrics)\n",
                "else:\n",
                "    print(\"Please run all the previouse cell before running this one!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "23K9XBBGOuCi"
            },
            "source": [
                "# Saving the parameters of the best model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "id": "MxFx9IoYMoha"
            },
            "outputs": [],
            "source": [
                "if (\"model_name\" in locals() or \"model_name\" in globals()) and (\"models\" in locals() or \"models\" in globals()):\n",
                "  params = None\n",
                "  if model_name == \"XGB Classifier\":\n",
                "    params = { k: v for k, v in models[model_name].get_xgb_params().items() if v is not None}\n",
                "  else:\n",
                "    params = { k: v for k, v in models[model_name].get_params().items() if v is not None}\n",
                "    \n",
                "  print(params)\n",
                "else:\n",
                "    print(\"Please run all the previouse cell before running this one!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Saving images of the best model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "outputs": [],
            "source": [
                "import shap\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "from PIL import Image\n",
                "from io import BytesIO\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "if (\"model_name\" in locals() or \"model_name\" in globals()) and (\"models\" in locals() or \"models\" in globals()) and (\"y_test\" in locals() or \"y_test\" in globals()):\n",
                "    predictions = models[model_name].predict(X_test)\n",
                "    cm = confusion_matrix(y_test, predictions)\n",
                "\n",
                "    plt.figure(figsize=(10, 7))\n",
                "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('True Label')\n",
                "\n",
                "    buf_conf = BytesIO()\n",
                "    plt.savefig(buf_conf, format='png')\n",
                "    plt.close()\n",
                "\n",
                "    buf_conf.seek(0)\n",
                "    conf_matrix = Image.open(buf_conf)\n",
                "\n",
                "    corr = df.corr()\n",
                "\n",
                "    plt.figure(figsize=(10, 7))\n",
                "    sns.heatmap(corr, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
                "    plt.title('Correlation Matrix')\n",
                "\n",
                "    buf_corr = BytesIO()\n",
                "    plt.savefig(buf_corr, format='png')\n",
                "    plt.close()\n",
                "\n",
                "    buf_corr.seek(0)\n",
                "    corr_matrix = Image.open(buf_corr)\n",
                "\n",
                "    # Saving SHAP plot for explainability.\n",
                "    explainer = shap.Explainer(models[model_name].predict, X_train)\n",
                "\n",
                "    shap_values = explainer(X_train)\n",
                "\n",
                "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\", show=False)\n",
                "\n",
                "    buf_shap = BytesIO()\n",
                "    plt.savefig(buf_shap, format='png')\n",
                "    buf_shap.seek(0)\n",
                "    plt.close()\n",
                "\n",
                "    shap_image = Image.open(buf_shap)\n",
                "\n",
                "    print(\"Finished Saving Images!\")\n",
                "else:\n",
                "    print(\"Please run all the previouse cell before running this one!\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Displaying Saved Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "outputs": [],
            "source": [
                "from IPython.display import display\n",
                "\n",
                "display(conf_matrix)\n",
                "display(corr_matrix)\n",
                "display(shap_image)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false
            },
            "source": [
                "# Save the model inside our model repository (Please run this cell only when you are satisfied with the result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "Tvs46pGrO_-R"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import datetime\n",
                "import mlflow\n",
                "import json\n",
                "import pandas as pd\n",
                "from mlflow import MlflowClient, MlflowException\n",
                "from sqlalchemy import create_engine, Column, String, DateTime, Numeric, Integer\n",
                "from sqlalchemy.orm import sessionmaker, declarative_base\n",
                "\n",
                "def is_variable_defined(var_name):\n",
                "    return var_name in locals() or var_name in globals()\n",
                "\n",
                "os.environ['MLFLOW_TRACKING_USERNAME'] = str(os.getenv(\"MLFLOW_TRACKING_USERNAME\")).strip().replace(\"\\n\", \"\")\n",
                "os.environ['MLFLOW_TRACKING_PASSWORD'] = str(os.getenv(\"MLFLOW_TRACKING_PASSWORD\")).strip().replace(\"\\n\", \"\")\n",
                "os.environ['AWS_ACCESS_KEY_ID'] = str(os.getenv(\"AWS_ACCESS_KEY_ID\")).strip().replace(\"\\n\", \"\")\n",
                "os.environ['AWS_SECRET_ACCESS_KEY'] = str(os.getenv(\"AWS_SECRET_ACCESS_KEY\")).strip().replace(\"\\n\", \"\")\n",
                "os.environ['MLFLOW_S3_ENDPOINT_URL'] = os.getenv(\"MLFLOW_S3_ENDPOINT_URL\")\n",
                "os.environ['MLFLOW_HTTP_REQUEST_TIMEOUT'] = \"1000\"\n",
                "\n",
                "if is_variable_defined(\"model_name\") and is_variable_defined(\"models\") and is_variable_defined(\"params\") and is_variable_defined(\"metrics\") and is_variable_defined(\"corr_matrix\") and is_variable_defined(\"conf_matrix\") and is_variable_defined(\"shap_image\"):\n",
                "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
                "    model_name = os.getenv(\"MODEL_NAME\").strip().replace(\"\\n\", \"\")\n",
                "    user_id = os.getenv(\"USER_ID\").strip().replace(\"\\n\", \"\")\n",
                "    register_name = f'{model_name}-{user_id}'\n",
                "\n",
                "    client = MlflowClient()\n",
                "\n",
                "    condition = None\n",
                "    try:\n",
                "        condition = client.get_registered_model(register_name)\n",
                "    except MlflowException as e:\n",
                "        print(e)\n",
                "\n",
                "    if condition is None:\n",
                "        with mlflow.start_run(experiment_id=mlflow.get_experiment_by_name(\"default\").experiment_id) as run:\n",
                "          mlflow.sklearn.log_model(models[model_name], \"model\")\n",
                "          mlflow.log_metrics(metrics)\n",
                "          mlflow.log_params(params)    \n",
                "          mlflow.log_image(corr_matrix, \"correlation_matrix.png\")\n",
                "          mlflow.log_image(conf_matrix, \"confusion_matrix.png\")\n",
                "          mlflow.log_image(shap_image, \"shap.png\")\n",
                "\n",
                "        run_id = run.info.run_id\n",
                "\n",
                "        src_uri = f\"runs:/{run_id}/model\"\n",
                "\n",
                "        description = \"\"\n",
                "        for k, v in encoded_df.dtypes.items():\n",
                "          description += f\"{k}:{v}; \"       \n",
                "\n",
                "        client.create_registered_model(register_name, description=f\"This model {os.getenv(\"MODEL_NAME\")} was trained on a dataset with this description having this columns: {description}.\")\n",
                "        mv = client.create_model_version(register_name, src_uri, run_id)\n",
                "        print(f\"Name: {mv.name}\")\n",
                "        print(f\"Version: {mv.version}\")\n",
                "        print(f\"Source: {mv.source}\")\n",
                "\n",
                "        Base = declarative_base()\n",
                "\n",
                "        class MyTable(Base):\n",
                "            __tablename__ = 'models'\n",
                "            model_id = Column(String, primary_key=True)\n",
                "            created_at = Column(DateTime)\n",
                "            user_id = Column(String)\n",
                "            dataset_user = Column(String)\n",
                "            description = Column(String)\n",
                "            score = Column(Numeric)\n",
                "            model_name = Column(String)\n",
                "            score_count = Column(Integer)\n",
                "            notebook_type = Column(String)\n",
                "\n",
                "        csv_data = {\n",
                "            \"column_dtypes\": {},\n",
                "            \"column_ranges\": {},\n",
                "            \"column_categories\": {},\n",
                "            \"column_unique_values\": {}\n",
                "        }\n",
                "\n",
                "        for column in df.columns:\n",
                "            if pd.api.types.is_numeric_dtype(df[column]):\n",
                "                csv_data[\"column_dtypes\"][column] = \"numeric\"\n",
                "                csv_data[\"column_ranges\"][column] = (min(df[column]), max(df[column]))\n",
                "                csv_data[\"column_categories\"][column] = None\n",
                "                csv_data[\"column_unique_values\"][column] = None\n",
                "            else:\n",
                "                if len(df[column].unique()) == len(df):\n",
                "                    csv_data[\"column_dtypes\"][column] = \"unique_identifier\"\n",
                "                    csv_data[\"column_ranges\"][column] = None\n",
                "                    csv_data[\"column_categories\"][column] = None\n",
                "                    csv_data[\"column_unique_values\"][column] = len(df[column].unique())\n",
                "                else:\n",
                "                    csv_data[\"column_dtypes\"][column] = \"categorical\"\n",
                "                    csv_data[\"column_ranges\"][column] = None\n",
                "                    csv_data[\"column_categories\"][column] = df[column].unique()\n",
                "                    csv_data[\"column_unique_values\"][column] = None\n",
                "\n",
                "        postgres_username = os.getenv(\"POSTGRES_USER\").strip().replace(\"\\n\", \"\")\n",
                "        postgres_password = os.getenv(\"POSTGRES_PASSWORD\").strip().replace(\"\\n\", \"\")\n",
                "        postgres_host = os.getenv(\"POSTGRES_HOST\").strip().replace(\"\\n\", \"\")\n",
                "        postgres_port = os.getenv(\"POSTGRES_PORT\").strip().replace(\"\\n\", \"\")\n",
                "        postgres_db = os.getenv(\"POSTGRES_DB\").strip().replace(\"\\n\", \"\")\n",
                "\n",
                "        engine = create_engine(f'postgresql+psycopg2://{postgres_username}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_db}')\n",
                "        Base.metadata.create_all(engine)\n",
                "\n",
                "        Session = sessionmaker(bind=engine)\n",
                "        session = Session()\n",
                "\n",
                "        with Session() as session:\n",
                "            new_row = MyTable(model_id=register_name, created_at=datetime.datetime.now(), user_id=user_id,\n",
                "                             description=json.dumps(csv_data), score=0.0, model_name=model_name, score_count=0, dataset_user=os.getenv(\"DATASET_USER\"), notebook_type=\"regression\")\n",
                "\n",
                "            session.add(new_row)\n",
                "\n",
                "            session.commit()\n",
                "    else:\n",
                "        print(\"You can only add the model once!\")\n",
                "else:\n",
                "    print(\"Please run all the previouse cell before running this one!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "xDWWZBa5U6wv"
            },
            "source": [
                "# Deleting the notebook. (Be careful when running this cell!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "id": "zTkN_mp5U6EY"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "from sqlalchemy.orm import sessionmaker, declarative_base\n",
                "from sqlalchemy import create_engine, Column, String, DateTime, Integer\n",
                "\n",
                "def is_variable_defined(var_name):\n",
                "    return var_name in locals() or var_name in globals()\n",
                "\n",
                "if is_variable_defined(\"model_name\") and is_variable_defined(\"models\") and is_variable_defined(\"params\") and is_variable_defined(\"metrics\") and is_variable_defined(\"corr_matrix\") and is_variable_defined(\"conf_matrix\") and is_variable_defined(\"shap_image\"):\n",
                "    Base = declarative_base()\n",
                "    \n",
                "    class MyTable(Base):\n",
                "        __tablename__ = 'notebooks'\n",
                "        user_id = Column(String)\n",
                "        created_at = Column(DateTime)\n",
                "        last_accessed = Column(DateTime)\n",
                "        notebook_id = Column(String, primary_key=True)\n",
                "        description = Column(String)\n",
                "        dataset_user = Column(String)\n",
                "        dataset_name = Column(String)\n",
                "        port = Column(Integer)\n",
                "        notebook_type = Column(String)\n",
                "    \n",
                "    \n",
                "    # Connect to the database\n",
                "    postgres_username = os.getenv(\"POSTGRES_USER\").strip().replace(\"\\n\", \"\")\n",
                "    postgres_password = os.getenv(\"POSTGRES_PASSWORD\").strip().replace(\"\\n\", \"\")\n",
                "    postgres_host = os.getenv(\"POSTGRES_HOST\").strip().replace(\"\\n\", \"\")\n",
                "    postgres_port = os.getenv(\"POSTGRES_PORT\").strip().replace(\"\\n\", \"\")\n",
                "    postgres_db = os.getenv(\"POSTGRES_DB\").strip().replace(\"\\n\", \"\")\n",
                "\n",
                "    engine = create_engine(f'postgresql+psycopg2://{postgres_username}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_db}')\n",
                "    Base.metadata.create_all(engine)\n",
                "    \n",
                "    # Create a session\n",
                "    Session = sessionmaker(bind=engine)\n",
                "    session = Session()\n",
                "    \n",
                "    notebook_id = os.getenv('NOTEBOOK_ID')\n",
                "    \n",
                "    # Query for the specific entry\n",
                "    row_count = session.query(MyTable).filter(MyTable.notebook_id == notebook_id).delete(synchronize_session='evaluate')\n",
                "    \n",
                "    if row_count > 0:\n",
                "        session.commit()\n",
                "    else:\n",
                "        print(\"Rows not found\")\n",
                "    \n",
                "    session.close()\n",
                "    \n",
                "    response = requests.get(f\"http://{os.getenv('SERVICE_NAME')}:{os.getenv('SERVICE_PORT')}\")\n",
                "    if response.status_code == 200:\n",
                "    \n",
                "        response = requests.delete(f\"http://{os.getenv('SERVICE_NAME')}:{os.getenv('SERVICE_PORT')}/delete_pod?uid={notebook_id}\")\n",
                "    \n",
                "        if response.status_code == 200:\n",
                "            print(\"Pod deleted successfully!\")\n",
                "else:\n",
                "    print(\"Please run all the previouse cell before running this one!\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyPMHfVOTf5YAyvYaf+TB3Jq",
            "gpuType": "T4",
            "machine_shape": "hm",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
